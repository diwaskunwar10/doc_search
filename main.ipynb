{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./rag/lib/python3.10/site-packages (0.1.16)\n",
      "Collecting rank-bm25\n",
      "  Using cached rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: PyPDF2 in ./rag/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: chromadb in ./rag/lib/python3.10/site-packages (0.4.24)\n",
      "Requirement already satisfied: requests<3,>=2 in ./rag/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./rag/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./rag/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./rag/lib/python3.10/site-packages (from langchain) (0.1.49)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./rag/lib/python3.10/site-packages (from langchain) (2.7.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./rag/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in ./rag/lib/python3.10/site-packages (from langchain) (0.0.34)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in ./rag/lib/python3.10/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./rag/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./rag/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in ./rag/lib/python3.10/site-packages (from langchain) (0.1.45)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./rag/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./rag/lib/python3.10/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./rag/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./rag/lib/python3.10/site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: build>=1.0.3 in ./rag/lib/python3.10/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: orjson>=3.9.12 in ./rag/lib/python3.10/site-packages (from chromadb) (3.10.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./rag/lib/python3.10/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./rag/lib/python3.10/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./rag/lib/python3.10/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./rag/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in ./rag/lib/python3.10/site-packages (from chromadb) (0.29.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./rag/lib/python3.10/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in ./rag/lib/python3.10/site-packages (from chromadb) (0.110.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./rag/lib/python3.10/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./rag/lib/python3.10/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./rag/lib/python3.10/site-packages (from chromadb) (0.45b0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in ./rag/lib/python3.10/site-packages (from chromadb) (4.66.2)\n",
      "Requirement already satisfied: importlib-resources in ./rag/lib/python3.10/site-packages (from chromadb) (6.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./rag/lib/python3.10/site-packages (from chromadb) (1.17.3)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./rag/lib/python3.10/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in ./rag/lib/python3.10/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./rag/lib/python3.10/site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./rag/lib/python3.10/site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in ./rag/lib/python3.10/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./rag/lib/python3.10/site-packages (from chromadb) (1.62.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./rag/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./rag/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: packaging>=19.1 in ./rag/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: tomli>=1.1.0 in ./rag/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: pyproject_hooks in ./rag/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./rag/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./rag/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in ./rag/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./rag/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in ./rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in ./rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in ./rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.29.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in ./rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./rag/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: coloredlogs in ./rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sympy in ./rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: protobuf in ./rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: flatbuffers in ./rag/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./rag/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in ./rag/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in ./rag/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in ./rag/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./rag/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in ./rag/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in ./rag/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in ./rag/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in ./rag/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in ./rag/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (59.6.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./rag/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./rag/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./rag/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in ./rag/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./rag/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in ./rag/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./rag/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./rag/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./rag/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in ./rag/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\n",
      "Requirement already satisfied: click>=8.0.0 in ./rag/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: rich>=10.11.0 in ./rag/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in ./rag/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: h11>=0.8 in ./rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in ./rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: websockets>=10.4 in ./rag/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./rag/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./rag/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./rag/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: filelock in ./rag/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./rag/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./rag/lib/python3.10/site-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.18.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./rag/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./rag/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in ./rag/lib/python3.10/site-packages (from starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (4.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./rag/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./rag/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./rag/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./rag/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./rag/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi>=0.95.2->chromadb) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./rag/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./rag/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
      "Installing collected packages: rank-bm25\n",
      "Successfully installed rank-bm25-0.2.2\n",
      "Collecting unstructured[pdf]\n",
      "  Using cached unstructured-0.13.3-py3-none-any.whl (1.9 MB)\n",
      "Collecting emoji\n",
      "  Using cached emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n",
      "Collecting rapidfuzz\n",
      "  Using cached rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "Collecting lxml\n",
      "  Using cached lxml-5.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "Requirement already satisfied: requests in ./rag/lib/python3.10/site-packages (from unstructured[pdf]) (2.31.0)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting python-iso639\n",
      "  Using cached python_iso639-2024.2.7-py3-none-any.whl (274 kB)\n",
      "Collecting langdetect\n",
      "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./rag/lib/python3.10/site-packages (from unstructured[pdf]) (4.11.0)\n",
      "Collecting unstructured-client\n",
      "  Using cached unstructured_client-0.22.0-py3-none-any.whl (28 kB)\n",
      "Collecting chardet\n",
      "  Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Collecting python-magic\n",
      "  Using cached python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting filetype\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: backoff in ./rag/lib/python3.10/site-packages (from unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: numpy in ./rag/lib/python3.10/site-packages (from unstructured[pdf]) (1.26.4)\n",
      "Requirement already satisfied: dataclasses-json in ./rag/lib/python3.10/site-packages (from unstructured[pdf]) (0.6.4)\n",
      "Requirement already satisfied: wrapt in ./rag/lib/python3.10/site-packages (from unstructured[pdf]) (1.16.0)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting pillow-heif\n",
      "  Downloading pillow_heif-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pikepdf\n",
      "  Downloading pikepdf-8.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pdf2image\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Collecting onnx\n",
      "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting unstructured-inference==0.7.27\n",
      "  Downloading unstructured_inference-0.7.27-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting unstructured.pytesseract>=0.3.12\n",
      "  Downloading unstructured.pytesseract-0.3.12-py3-none-any.whl (14 kB)\n",
      "Collecting pdfminer.six\n",
      "  Using cached pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: pypdf in ./rag/lib/python3.10/site-packages (from unstructured[pdf]) (4.2.0)\n",
      "Requirement already satisfied: transformers>=4.25.1 in ./rag/lib/python3.10/site-packages (from unstructured-inference==0.7.27->unstructured[pdf]) (4.40.0)\n",
      "Requirement already satisfied: huggingface-hub in ./rag/lib/python3.10/site-packages (from unstructured-inference==0.7.27->unstructured[pdf]) (0.22.2)\n",
      "Collecting layoutparser[layoutmodels,tesseract]\n",
      "  Downloading layoutparser-0.3.4-py3-none-any.whl (19.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-multipart\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: onnxruntime>=1.17.0 in ./rag/lib/python3.10/site-packages (from unstructured-inference==0.7.27->unstructured[pdf]) (1.17.3)\n",
      "Collecting opencv-python!=4.7.0.68\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=8.0.0 in ./rag/lib/python3.10/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (10.3.0)\n",
      "Requirement already satisfied: packaging>=21.3 in ./rag/lib/python3.10/site-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (23.2)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./rag/lib/python3.10/site-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./rag/lib/python3.10/site-packages (from dataclasses-json->unstructured[pdf]) (3.21.1)\n",
      "Requirement already satisfied: six in ./rag/lib/python3.10/site-packages (from langdetect->unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./rag/lib/python3.10/site-packages (from nltk->unstructured[pdf]) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in ./rag/lib/python3.10/site-packages (from nltk->unstructured[pdf]) (4.66.2)\n",
      "Requirement already satisfied: click in ./rag/lib/python3.10/site-packages (from nltk->unstructured[pdf]) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./rag/lib/python3.10/site-packages (from nltk->unstructured[pdf]) (1.4.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./rag/lib/python3.10/site-packages (from onnx->unstructured[pdf]) (4.25.3)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./rag/lib/python3.10/site-packages (from pdfminer.six->unstructured[pdf]) (3.3.2)\n",
      "Collecting cryptography>=36.0.0\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Requirement already satisfied: Deprecated in ./rag/lib/python3.10/site-packages (from pikepdf->unstructured[pdf]) (1.2.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./rag/lib/python3.10/site-packages (from requests->unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./rag/lib/python3.10/site-packages (from requests->unstructured[pdf]) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./rag/lib/python3.10/site-packages (from requests->unstructured[pdf]) (2024.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in ./rag/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
      "Collecting jsonpath-python>=1.0.6\n",
      "  Using cached jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Collecting deepdiff>=6.0\n",
      "  Using cached deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./rag/lib/python3.10/site-packages (from unstructured-client->unstructured[pdf]) (2.9.0.post0)\n",
      "Collecting cffi>=1.12\n",
      "  Using cached cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "Collecting ordered-set<4.2.0,>=4.1.0\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: sympy in ./rag/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.27->unstructured[pdf]) (1.12)\n",
      "Requirement already satisfied: flatbuffers in ./rag/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.27->unstructured[pdf]) (24.3.25)\n",
      "Requirement already satisfied: coloredlogs in ./rag/lib/python3.10/site-packages (from onnxruntime>=1.17.0->unstructured-inference==0.7.27->unstructured[pdf]) (15.0.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./rag/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.27->unstructured[pdf]) (0.19.1)\n",
      "Requirement already satisfied: filelock in ./rag/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.27->unstructured[pdf]) (3.13.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./rag/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.27->unstructured[pdf]) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./rag/lib/python3.10/site-packages (from transformers>=4.25.1->unstructured-inference==0.7.27->unstructured[pdf]) (0.4.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./rag/lib/python3.10/site-packages (from huggingface-hub->unstructured-inference==0.7.27->unstructured[pdf]) (2024.3.1)\n",
      "Collecting iopath\n",
      "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pandas\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Requirement already satisfied: scipy in ./rag/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (1.13.0)\n",
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytesseract\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Collecting effdet\n",
      "  Downloading effdet-0.4.1-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in ./rag/lib/python3.10/site-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (2.2.2)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.17.2-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycparser\n",
      "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./rag/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.17.0->unstructured-inference==0.7.27->unstructured[pdf]) (10.0)\n",
      "Collecting timm>=0.9.2\n",
      "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf>=2.0\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pycocotools>=2.0.2\n",
      "  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (3.1.3)\n",
      "Requirement already satisfied: triton==2.2.0 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (2.2.0)\n",
      "Requirement already satisfied: networkx in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./rag/lib/python3.10/site-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./rag/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (12.4.127)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting pypdfium2>=4.18.0\n",
      "  Downloading pypdfium2-4.29.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in ./rag/lib/python3.10/site-packages (from sympy->onnxruntime>=1.17.0->unstructured-inference==0.7.27->unstructured[pdf]) (1.3.0)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m404.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m336.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib>=2.1.0\n",
      "  Using cached matplotlib-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./rag/lib/python3.10/site-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.27->unstructured[pdf]) (2.1.5)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.51.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (305 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using legacy 'setup.py install' for langdetect, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for iopath, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for antlr4-python3-runtime, since package 'wheel' is not installed.\n",
      "Installing collected packages: pytz, filetype, antlr4-python3-runtime, unstructured.pytesseract, tzdata, tabulate, soupsieve, rapidfuzz, python-multipart, python-magic, python-iso639, pytesseract, pypdfium2, pyparsing, pycparser, portalocker, pillow-heif, pdf2image, ordered-set, opencv-python, onnx, omegaconf, nltk, lxml, langdetect, kiwisolver, jsonpath-python, fonttools, emoji, cycler, contourpy, chardet, pikepdf, pandas, matplotlib, iopath, deepdiff, cffi, beautifulsoup4, unstructured-client, pycocotools, cryptography, unstructured, torchvision, pdfminer.six, timm, pdfplumber, layoutparser, effdet, unstructured-inference\n",
      "  Running setup.py install for antlr4-python3-runtime ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for langdetect ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for iopath ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed antlr4-python3-runtime-4.9.3 beautifulsoup4-4.12.3 cffi-1.16.0 chardet-5.2.0 contourpy-1.2.1 cryptography-42.0.5 cycler-0.12.1 deepdiff-7.0.1 effdet-0.4.1 emoji-2.11.1 filetype-1.2.0 fonttools-4.51.0 iopath-0.1.10 jsonpath-python-1.0.6 kiwisolver-1.4.5 langdetect-1.0.9 layoutparser-0.3.4 lxml-5.2.1 matplotlib-3.8.4 nltk-3.8.1 omegaconf-2.3.0 onnx-1.16.0 opencv-python-4.9.0.80 ordered-set-4.1.0 pandas-2.2.2 pdf2image-1.17.0 pdfminer.six-20231228 pdfplumber-0.11.0 pikepdf-8.15.1 pillow-heif-0.16.0 portalocker-2.8.2 pycocotools-2.0.7 pycparser-2.22 pyparsing-3.1.2 pypdfium2-4.29.0 pytesseract-0.3.10 python-iso639-2024.2.7 python-magic-0.4.27 python-multipart-0.0.9 pytz-2024.1 rapidfuzz-3.8.1 soupsieve-2.5 tabulate-0.9.0 timm-0.9.16 torchvision-0.17.2 tzdata-2024.1 unstructured-0.13.3 unstructured-client-0.22.0 unstructured-inference-0.7.27 unstructured.pytesseract-0.3.12\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Requirement already satisfied: pytesseract in ./rag/lib/python3.10/site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in ./rag/lib/python3.10/site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in ./rag/lib/python3.10/site-packages (from pytesseract) (10.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install langchain, rank-bm25, PyPDF2, unstructured, chromadb\n",
    "!pip install langchain rank-bm25 PyPDF2 chromadb\n",
    "\n",
    "# Install extra dependencies for handling PDFs\n",
    "!pip install unstructured['pdf'] \n",
    "\n",
    "# Install poppler-utils for PDF processing\n",
    "!apt-get install -y poppler-utils\n",
    "\n",
    "# Install tesseract-ocr and its dependencies\n",
    "!apt-get install -y tesseract-ocr libtesseract-dev\n",
    "\n",
    "# Install pytesseract for OCR capabilities\n",
    "!pip install pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader,UnstructuredPDFLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face API Key: ########################################"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "hf_api_key = os.getenv(\"hf_key\")\n",
    "print(\"Hugging Face API Key:\", hf_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/diwas/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/diwas/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"./data/yolo.pdf\"\n",
    "data_file = UnstructuredPDFLoader(file_path)\n",
    "docs = data_file.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chunks\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "chunks = splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=hf_api_key,\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store\n",
    "vectorstore = Chroma.from_documents(chunks, embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector store retriever\n",
    "vectorstore_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create keyword retriever\n",
    "keyword_retriever = BM25Retriever.from_documents(chunks)\n",
    "keyword_retriever.k = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[vectorstore_retriever, keyword_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diwas/Documents/rag/rag/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n",
      "/home/diwas/Documents/rag/rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Create LLM\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    model_kwargs={\"temperature\": 0.3, \"max_new_tokens\": 1024},\n",
    "    huggingfacehub_api_token=hf_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "<|system|>>\n",
    "You are a helpful AI assistant that follows instruction extremely well .\n",
    "Use the following  context to answer user question.\n",
    "CONTEXT:{context}\n",
    "</s>\n",
    "<|user|>\n",
    "{query}\n",
    "</s>\n",
    "<|assistant|>      \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt template\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser=StrOutputParser()\n",
    "chain=(\n",
    "    {\"context\":ensemble_retriever,\"query\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "<|system|>>\n",
      "You are a helpful AI assistant that follows instruction extremely well .\n",
      "Use the following  copntext to answer user question.\n",
      "\n",
      "CONTEXT:[Document(page_content='including the time to fetch images from the camera and dis- play the detections.\\n\\nThe resulting system is interactive and engaging. While YOLO processes images individually, when attached to a webcam it functions like a tracking system, detecting ob- jects as they move around and change in appearance. A demo of the system and the source code can be found on our project website: http://pjreddie.com/yolo/.\\n\\ndirectly on full images. Unlike classiﬁer-based approaches, YOLO is trained on a loss function that directly corresponds to detection performance and the entire model is trained jointly.', metadata={'source': './data/yolo.pdf'}), Document(page_content='the test data can diverge from what the system has seen be- fore [3]. We compare YOLO to other detection systems on the Picasso Dataset [12] and the People-Art Dataset [3], two datasets for testing person detection on artwork.\\n\\nThe boost from YOLO is not simply a byproduct of model ensembling since there is little beneﬁt from combin- ing different versions of Fast R-CNN. Rather, it is precisely because YOLO makes different kinds of mistakes at test time that it is so effective at boosting Fast R-CNN’s per- formance.', metadata={'source': './data/yolo.pdf'}), Document(page_content='1. Resize image.2. Run convolutional network.3. Non-max suppression. Horse: 0.28\\n\\nFigure 1: The YOLO Detection System. Processing images with YOLO is simple and straightforward. Our system (1) resizes the input image to 448 × 448, (2) runs a single convolutional net- work on the image, and (3) thresholds the resulting detections by the model’s conﬁdence.', metadata={'source': './data/yolo.pdf'}), Document(page_content='R-CNN minus R replaces Selective Search with static bounding box proposals [20]. While it is much faster than\\n\\nReal-Time Detectors 100Hz DPM [31] 30Hz DPM [31] Fast YOLO YOLO Less Than Real-Time Fastest DPM [38] R-CNN Minus R [20] Fast R-CNN [14] Faster R-CNN VGG-16[28] Faster R-CNN ZF [28] YOLO VGG-16\\n\\nTrain mAP 16.0 2007 26.1 2007 52.7 2007+2012 63.4 2007+2012\\n\\n2007 2007 2007+2012 2007+2012 2007+2012 2007+2012\\n\\n30.4 53.5 70.0 73.2 62.1 66.4\\n\\nTable 1: Real-Time Systems on PASCAL VOC 2007. Compar- ing the performance and speed of fast detectors. Fast YOLO is the fastest detector on record for PASCAL VOC detection and is still twice as accurate as any other real-time detector. YOLO is 10 mAP more accurate than the fast version while still well above real-time in speed.', metadata={'source': './data/yolo.pdf'}), Document(page_content='Table 3: PASCAL VOC 2012 Leaderboard. YOLO compared with the full comp4 (outside data allowed) public leaderboard as of November 6th, 2015. Mean average precision and per-class average precision are shown for a variety of detection methods. YOLO is the only real-time detector. Fast R-CNN + YOLO is the forth highest scoring method, with a 2.3% boost over Fast R-CNN.\\n\\nmAP increases by 3.2% to 75.0%. We also tried combining the top Fast R-CNN model with several other versions of Fast R-CNN. Those ensembles produced small increases in mAP between .3 and .6%, see Table 2 for details.', metadata={'source': './data/yolo.pdf'}), Document(page_content='Fast YOLO is the fastest object detection method on PASCAL; as far as we know, it is the fastest extant object detector. With 52.7% mAP, it is more than twice as accurate as prior work on real-time detection. YOLO pushes mAP to 63.4% while still maintaining real-time performance.\\n\\nWe also train YOLO using VGG-16. This model is more accurate but also signiﬁcantly slower than YOLO. It is use- ful for comparison to other detection systems that rely on VGG-16 but since it is slower than real-time the rest of the paper focuses on our faster models.\\n\\nFastest DPM effectively speeds up DPM without sacri- ﬁcing much mAP but it still misses real-time performance by a factor of 2 [38]. It also is limited by DPM’s relatively low accuracy on detection compared to neural network ap- proaches.', metadata={'source': './data/yolo.pdf'})]\n",
      "</s>\n",
      "<|user|>\n",
      "What is  YOLO\n",
      "</s>\n",
      "<|assistant|>      \n",
      "YOLO (You Only Look Once) is a real-time object detection system designed to be both fast and accurate. It is different from traditional object detection methods, such as classifiers, as it is trained on a loss function that directly corresponds to detection performance, and the entire model is trained jointly. The resulting system is interactive and engaging, as it functions like a tracking system, detecting objects as they move around and change in appearance, even when attached to a webcam. YOLO is trained on the Pascal VOC and COCO datasets, and it has achieved state-of-the-art results in real-time object detection. The system is simple and straightforward to use, as it involves resizing the input image, running a single convolutional network, and thresholding the resulting detections by the model's confidence. YOLO is also faster than other real-time detection methods, such as DPM and Faster R-CNN, while still maintaining high accuracy. Overall, YOLO is a powerful and efficient object detection system that has gained popularity in the computer vision community.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What is  YOLO\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "<|system|>>\n",
      "You are a helpful AI assistant that follows instruction extremely well .\n",
      "Use the following  copntext to answer user question.\n",
      "\n",
      "CONTEXT:[Document(page_content='3. Comparison to Other Detection Systems\\n\\nObject detection is a core problem in computer vision. Detection pipelines generally start by extracting a set of robust features from input images (Haar [25], SIFT [23], HOG [4], convolutional features [6]). Then, classiﬁers [36, 21, 13, 10] or localizers [1, 32] are used to identify objects in the feature space. These classiﬁers or localizers are run either in sliding window fashion over the whole im- age or on some subset of regions in the image [35, 15, 39]. We compare the YOLO detection system to several top de- tection frameworks, highlighting key similarities and differ- ences.', metadata={'source': './data/yolo.pdf'}), Document(page_content='2. Uniﬁed Detection\\n\\nWe unify the separate components of object detection into a single neural network. Our network uses features from the entire image to predict each bounding box. It also predicts all bounding boxes across all classes for an im- age simultaneously. This means our network reasons glob- ally about the full image and all the objects in the image. The YOLO design enables end-to-end training and real- time speeds while maintaining high average precision.\\n\\nOur system divides the input image into an S × S grid. If the center of an object falls into a grid cell, that grid cell is responsible for detecting that object.', metadata={'source': './data/yolo.pdf'}), Document(page_content='4.5. Generalizability: Person Detection in Artwork\\n\\n5. Real-Time Detection In The Wild\\n\\nAcademic datasets for object detection draw the training and testing data from the same distribution. In real-world applications it is hard to predict all possible use cases and\\n\\nYOLO is a fast, accurate object detector, making it ideal for computer vision applications. We connect YOLO to a webcam and verify that it maintains real-time performance,\\n\\ntv 74.0 65.7 65.6 67.2 72.1 61.5 71.4 68.1 64.2 66.2 63.3 62.6 62.7 60.3 58.7 50.8 57.8 54.1 50.7 51.6\\n\\nPoseletsRCNND&THumansDPMYOLO\\n\\nYOLO R-CNN DPM Poselets [2] D&T [4]\\n\\nVOC 2007 AP 59.2 54.2 43.2 36.5 -\\n\\nPicasso AP Best F1 0.590 53.3 0.226 10.4 0.458 37.8 0.271 17.8 0.051 1.9\\n\\nPeople-Art AP 45 26 32\\n\\n(a) Picasso Dataset precision-recall curves.', metadata={'source': './data/yolo.pdf'}), Document(page_content='6 1 0 2\\n\\ny a M 9\\n\\n]\\n\\nV C . s c [\\n\\n5 v 0 4 6 2 0 . 6 0 5 1 : v i X r a\\n\\nYou Only Look Once: Uniﬁed, Real-Time Object Detection\\n\\nJoseph Redmon∗, Santosh Divvala∗†, Ross Girshick¶, Ali Farhadi∗† University of Washington∗, Allen Institute for AI†, Facebook AI Research¶ http://pjreddie.com/yolo/\\n\\nAbstract', metadata={'source': './data/yolo.pdf'}), Document(page_content='1. Resize image.2. Run convolutional network.3. Non-max suppression. Horse: 0.28\\n\\nFigure 1: The YOLO Detection System. Processing images with YOLO is simple and straightforward. Our system (1) resizes the input image to 448 × 448, (2) runs a single convolutional net- work on the image, and (3) thresholds the resulting detections by the model’s conﬁdence.', metadata={'source': './data/yolo.pdf'})]\n",
      "</s>\n",
      "<|user|>\n",
      "What is Unified Detection\n",
      "</s>\n",
      "<|assistant|>      \n",
      "Unified Detection, as described in the context provided, refers to the approach of combining separate components of object detection into a single neural network. This method uses features from the entire image to predict each bounding box and predicts all bounding boxes across all classes for an image simultaneously. This allows the network to reason globally about the full image and all objects in the image, enabling end-to-end training and real-time speeds while maintaining high average precision. The YOLO (You Only Look Once) detection system, which is being compared to other detection frameworks in the context, implements this unified detection approach.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What is Unified Detection\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "<|system|>>\n",
      "You are a helpful AI assistant that follows instruction extremely well .\n",
      "Use the following  copntext to answer user question.\n",
      "\n",
      "CONTEXT:[Document(page_content='We also train a fast version of YOLO designed to push the boundaries of fast object detection. Fast YOLO uses a neural network with fewer convolutional layers (9 instead of 24) and fewer ﬁlters in those layers. Other than the size of the network, all training and testing parameters are the same between YOLO and Fast YOLO.\\n\\n(1)\\n\\n33\\n\\n4096\\n\\n7730} ×4} ×2Conv. Layers3x3x10243x3x1024\\n\\n5656256Conn. Layer\\n\\n33\\n\\nConn. LayerConv. Layer3x3x192Maxpool Layer2x2-s-2Conv. Layers1x1x1283x3x2561x1x2563x3x512Maxpool Layer2x2-s-2\\n\\n33\\n\\n2828512Conv. Layers1x1x2563x3x5121x1x5123x3x1024Maxpool Layer2x2-s-2\\n\\n33\\n\\n771024\\n\\n112112192\\n\\n77Conv. Layer7x7x64-s-2Maxpool Layer2x2-s-2\\n\\n771024\\n\\n4484483\\n\\n14141024Conv. Layers1x1x5123x3x10243x3x10243x3x1024-s-2\\n\\n33', metadata={'source': './data/yolo.pdf'}), Document(page_content='1. Resize image.2. Run convolutional network.3. Non-max suppression. Horse: 0.28\\n\\nFigure 1: The YOLO Detection System. Processing images with YOLO is simple and straightforward. Our system (1) resizes the input image to 448 × 448, (2) runs a single convolutional net- work on the image, and (3) thresholds the resulting detections by the model’s conﬁdence.', metadata={'source': './data/yolo.pdf'}), Document(page_content='(3)\\n\\nthe border of multiple cells can be well localized by multi- ple cells. Non-maximal suppression can be used to ﬁx these multiple detections. While not critical to performance as it is for R-CNN or DPM, non-maximal suppression adds 2- 3% in mAP.\\n\\n2.4. Limitations of YOLO\\n\\nYOLO imposes strong spatial constraints on bounding box predictions since each grid cell only predicts two boxes and can only have one class. This spatial constraint lim- its the number of nearby objects that our model can pre- dict. Our model struggles with small objects that appear in groups, such as ﬂocks of birds.', metadata={'source': './data/yolo.pdf'}), Document(page_content='4.2. VOC 2007 Error Analysis\\n\\nTo further examine the differences between YOLO and state-of-the-art detectors, we look at a detailed breakdown of results on VOC 2007. We compare YOLO to Fast R- CNN since Fast R-CNN is one of the highest performing detectors on PASCAL and it’s detections are publicly avail- able.\\n\\nWe use the methodology and tools of Hoiem et al. [19] For each category at test time we look at the top N predic- tions for that category. Each prediction is either correct or it is classiﬁed based on the type of error:\\n\\nCorrect: correct class and IOU > .5\\n\\nLocalization: correct class, .1 < IOU < .5\\n\\nSimilar: class is similar, IOU > .1\\n\\nFPS 100 30 155 45\\n\\n15 6 0.5 7 18 21', metadata={'source': './data/yolo.pdf'}), Document(page_content='DPM maintains its AP well when applied to artwork. Prior work theorizes that DPM performs well because it has strong spatial models of the shape and layout of objects. Though DPM doesn’t degrade as much as R-CNN, it starts from a lower AP.\\n\\nYOLO has good performance on VOC 2007 and its AP degrades less than other methods when applied to artwork. Like DPM, YOLO models the size and shape of objects, as well as relationships between objects and where objects commonly appear. Artwork and natural images are very different on a pixel level but they are similar in terms of the size and shape of objects, thus YOLO can still predict good bounding boxes and detections.\\n\\n4.5. Generalizability: Person Detection in Artwork\\n\\n5. Real-Time Detection In The Wild', metadata={'source': './data/yolo.pdf'})]\n",
      "</s>\n",
      "<|user|>\n",
      "What are the Limitations of YOLO\n",
      "</s>\n",
      "<|assistant|>      \n",
      "According to the context provided, the limitations of YOLO are:\n",
      "\n",
      "1. Strong spatial constraints on bounding box predictions: Each grid cell in the input image can only predict two boxes and can only have one class, which limits the number of nearby objects that the model can predict.\n",
      "\n",
      "2. Struggles with small objects that appear in groups: The spatial constraint of predicting only two boxes per grid cell makes it difficult for the model to accurately predict the location of multiple nearby small objects, such as flocks of birds.\n",
      "\n",
      "These limitations can result in lower performance for YOLO compared to other state-of-the-art detectors, particularly for detecting small objects in groups. However, the context also mentions that YOLO still performs well for detecting objects in artwork, which suggests that it can still predict good bounding boxes and detections for images with similar size and shape of objects as natural images.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What are the Limitations of YOLO\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
